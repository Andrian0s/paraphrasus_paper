{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T12:52:16.561409Z",
     "start_time": "2024-12-11T12:52:16.052110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def find_unique_column_names(directory_path):\n",
    "    \"\"\"\n",
    "    Finds unique column names across all TSV files in a given directory.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): Path to the directory containing TSV files.\n",
    "\n",
    "    Returns:\n",
    "        set: A set of unique column names from all TSV files.\n",
    "    \"\"\"\n",
    "    unique_columns = set()\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        # Check if the file is a TSV file\n",
    "        if filename.endswith('.tsv'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                # Read the TSV file into a DataFrame\n",
    "                df = pd.read_csv(file_path, sep='\\t', nrows=1)  # Read only the header row for efficiency\n",
    "                # Update the set of unique columns\n",
    "                unique_columns.update(df.columns)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    return unique_columns\n",
    "\n",
    "# Example usage\n",
    "directory_path = \"original_reproduction_code/datasets\"  # Replace with the path to your directory\n",
    "unique_columns = find_unique_column_names(directory_path)\n",
    "\n",
    "prefixes = [\n",
    "    # \"CLEAN-\",\n",
    "    \"XLM-RoBERTa-EN-\",\n",
    "    \"LLama3 zero-shot\",\n",
    "    \"LLama3 ICL_4\"\n",
    "]\n",
    "def is_column_of_interest(column_name):\n",
    "    for prefix in prefixes:\n",
    "        if column_name.lower().startswith(prefix.lower()):\n",
    "            return True\n",
    "cols_of_interest = [c for c in unique_columns if is_column_of_interest(c)]\n",
    "\n",
    "print(\"\\n\".join(sorted(list(cols_of_interest))))"
   ],
   "id": "b28e26311dfce2d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLama3 ICL_4 (Ex. Same Content)\n",
      "LLama3 ICL_4 (Paraph)\n",
      "LLama3 ICL_4 (Sem Equiv)\n",
      "LLama3 zero-shot (Ex. Same Content)\n",
      "LLama3 zero-shot (Paraph)\n",
      "LLama3 zero-shot (Sem Equiv)\n",
      "XLM-RoBERTa-EN-ALLTHREE-V2-1\n",
      "XLM-RoBERTa-EN-ALLTHREE-V2-2\n",
      "XLM-RoBERTa-EN-ALLTHREE-V2-3\n",
      "XLM-RoBERTa-EN-ALLTHREE-V3-1\n",
      "XLM-RoBERTa-EN-ALLTHREE-V3-2\n",
      "XLM-RoBERTa-EN-ALLTHREE-V3-3\n",
      "XLM-RoBERTa-EN-ALLTHREE-V3-4\n",
      "XLM-RoBERTa-EN-ALLTHREE-V4-1\n",
      "XLM-RoBERTa-EN-ALLTHREE-V4-2\n",
      "XLM-RoBERTa-EN-ALLTHREE-V4-3\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V2-1\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V2-2\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V2-3\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V3-1\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V3-2\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V3-3\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V4-1\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V4-2\n",
      "XLM-RoBERTa-EN-EASYNEG-25-V4-3\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V2-1\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V2-2\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V2-3\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V3-1\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V3-2\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V3-3\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V4-1\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V4-2\n",
      "XLM-RoBERTa-EN-EASYNEG-50-V4-3\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V2-1\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V2-2\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V2-3\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V3-1\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V3-2\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V3-3\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V4-1\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V4-2\n",
      "XLM-RoBERTa-EN-EASYNEG-75-V4-3\n",
      "XLM-RoBERTa-EN-ORIG-V2-1\n",
      "XLM-RoBERTa-EN-ORIG-V2-2\n",
      "XLM-RoBERTa-EN-ORIG-V2-3\n",
      "XLM-RoBERTa-EN-ORIG-V3-1\n",
      "XLM-RoBERTa-EN-ORIG-V3-2\n",
      "XLM-RoBERTa-EN-ORIG-V3-3\n",
      "XLM-RoBERTa-EN-ORIG-V4-2\n",
      "XLM-RoBERTa-EN-ORIG-V4-3\n",
      "XLM-RoBERTa-EN-PARAPH-V2-1\n",
      "XLM-RoBERTa-EN-PARAPH-V2-2\n",
      "XLM-RoBERTa-EN-PARAPH-V2-3\n",
      "XLM-RoBERTa-EN-PARAPH-V3-1\n",
      "XLM-RoBERTa-EN-PARAPH-V3-2\n",
      "XLM-RoBERTa-EN-PARAPH-V3-3\n",
      "XLM-RoBERTa-EN-PARAPH-V4-1\n",
      "XLM-RoBERTa-EN-PARAPH-V4-2\n",
      "XLM-RoBERTa-EN-PARAPH-V4-3\n",
      "XLM-RoBERTa-EN-SAMECONTENT-V2-2\n",
      "XLM-RoBERTa-EN-SAMECONTENT-V2-3\n",
      "XLM-RoBERTa-EN-SAMECONTENT-V3-1\n",
      "XLM-RoBERTa-EN-SAMECONTENT-V3-2\n",
      "XLM-RoBERTa-EN-SAMECONTENT-V3-3\n",
      "XLM-RoBERTa-EN-SAMECONTENT-V4-1\n",
      "XLM-RoBERTa-EN-SAMECONTENT-V4-2\n",
      "XLM-RoBERTa-EN-SAMECONTENT-V4-3\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V2-1\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V2-2\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V2-3\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V3-1\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V3-2\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V3-3\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V4-1\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V4-2\n",
      "XLM-RoBERTa-EN-SEMEQUIV-V4-3\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T12:52:16.566164Z",
     "start_time": "2024-12-11T12:52:16.564368Z"
    }
   },
   "cell_type": "code",
   "source": [
    "name_mapping = {\n",
    "    'stsbenchmark': 'stsbenchmark-test-sts',\n",
    "    'ms_mrpc': 'ms-mrpc',\n",
    "    'onestop_all': 'onestop_parallel_all_pairs',\n",
    "    'simple_amr': 'amr_true_paraphrases',\n",
    "    'fb_anli_pre_hyp': 'fb-anli-pre-hyp',\n",
    "    'fb_anli_hyp_pre': 'fb-anli-hyp-pre',\n",
    "    'sickr_sts': 'sickr-sts',\n",
    "    'pawsx_test': 'paws-x-test',\n",
    "    'stanfordnlp_snli_pre_hyp': 'stannlp-snli-pre-hyp',\n",
    "    'fb_xnli_pre_hyp': 'fb-xnli-pre-hyp',\n",
    "    'fb_xnli_hyp_pre': 'fb-xnli-hyp-pre',\n",
    "    'stanfordnlp_snli_hyp_pre': 'stannlp-snli-hyp-pre'\n",
    "}\n",
    "\n",
    "NO_ID_KEY = \"NOID\"\n",
    "ID_KEY = \"id\"\n",
    "id_mapping = {\n",
    "    'stsbenchmark': ID_KEY,\n",
    "    'ms_mrpc': NO_ID_KEY,\n",
    "    'onestop_all': 'OriginalID',\n",
    "    'simple_amr': NO_ID_KEY,\n",
    "    'fb_anli_pre_hyp': ID_KEY,\n",
    "    'fb_anli_hyp_pre': ID_KEY,\n",
    "    'sickr_sts': ID_KEY,\n",
    "    'pawsx_test': ID_KEY,\n",
    "    'stanfordnlp_snli_pre_hyp': ID_KEY,\n",
    "    'fb_xnli_pre_hyp': ID_KEY,\n",
    "    'fb_xnli_hyp_pre': ID_KEY,\n",
    "    'stanfordnlp_snli_hyp_pre': ID_KEY,\n",
    "}"
   ],
   "id": "4b0f87ad2031b1c1",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T13:16:13.583243Z",
     "start_time": "2024-12-11T13:16:06.960687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "def get_original_data(key: str)->pd.DataFrame:\n",
    "    fname = name_mapping[key]+\".tsv\"\n",
    "    path = os.path.join(\"original_reproduction_code/datasets\", fname)\n",
    "    return pd.read_csv(path, sep='\\t')\n",
    "def save_paper_json_dict(key: str, dict):\n",
    "    fname = name_mapping[key]+\".json\"\n",
    "    path = os.path.join(\"benches/paper\", fname)\n",
    "    print(f\"reading {path}\")\n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(dict, f, indent=2)\n",
    "def get_paper_json_dict(key: str)->dict:\n",
    "    fname = name_mapping[key]+\".json\"\n",
    "    path = os.path.join(\"benches/paper\", fname)\n",
    "    print(f\"reading {path}\")\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def add_data_record(dataset_key:str, i:int, paper_element: pd.Series, json_dict):\n",
    "    id_field = id_mapping[dataset_key]\n",
    "    if id_field == NO_ID_KEY:\n",
    "        id = f\"{dataset_key}/{i}\"\n",
    "    else:\n",
    "        id = paper_element[id_field]\n",
    "    if id not in json_dict.keys():\n",
    "        id = f\"{id}\"\n",
    "        if id not in json_dict.keys():\n",
    "            print(f\"ERROR! [id field is {id_field}]{id} is not found in the dataset {dataset_key}. Dict keys: {json_dict.keys()}\")\n",
    "            exit(1)\n",
    "\n",
    "    for col in paper_element.keys():\n",
    "        if col in cols_of_interest:\n",
    "            paper_value = paper_element[col]\n",
    "            if paper_value == 1:\n",
    "                json_dict[id][col] = True\n",
    "            elif paper_value == 0:\n",
    "                json_dict[id][col] = False\n",
    "            else:\n",
    "                print(f\"Unexpected value {paper_value} for {col}: {paper_element}\")\n",
    "\n",
    "\n",
    "\n",
    "for dataset_key in name_mapping.keys():\n",
    "    df = get_original_data(dataset_key)\n",
    "    json_dict = get_paper_json_dict(dataset_key)\n",
    "    for i, element in df.iterrows():\n",
    "        add_data_record(dataset_key, i, element, json_dict)\n",
    "    save_paper_json_dict(dataset_key, json_dict)\n",
    "    # add_data_record(dataset_key, id_mapping[dataset_key], json_dict, json_dict)\n",
    "\n",
    "\n"
   ],
   "id": "19241af95961238f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading benches/paper/stsbenchmark-test-sts.json\n",
      "reading benches/paper/stsbenchmark-test-sts.json\n",
      "reading benches/paper/ms-mrpc.json\n",
      "reading benches/paper/ms-mrpc.json\n",
      "reading benches/paper/onestop_parallel_all_pairs.json\n",
      "reading benches/paper/onestop_parallel_all_pairs.json\n",
      "reading benches/paper/amr_true_paraphrases.json\n",
      "reading benches/paper/amr_true_paraphrases.json\n",
      "reading benches/paper/fb-anli-pre-hyp.json\n",
      "reading benches/paper/fb-anli-pre-hyp.json\n",
      "reading benches/paper/fb-anli-hyp-pre.json\n",
      "reading benches/paper/fb-anli-hyp-pre.json\n",
      "reading benches/paper/sickr-sts.json\n",
      "reading benches/paper/sickr-sts.json\n",
      "reading benches/paper/paws-x-test.json\n",
      "reading benches/paper/paws-x-test.json\n",
      "reading benches/paper/stannlp-snli-pre-hyp.json\n",
      "reading benches/paper/stannlp-snli-pre-hyp.json\n",
      "reading benches/paper/fb-xnli-pre-hyp.json\n",
      "reading benches/paper/fb-xnli-pre-hyp.json\n",
      "reading benches/paper/fb-xnli-hyp-pre.json\n",
      "reading benches/paper/fb-xnli-hyp-pre.json\n",
      "reading benches/paper/stannlp-snli-hyp-pre.json\n",
      "reading benches/paper/stannlp-snli-hyp-pre.json\n"
     ]
    }
   ],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
